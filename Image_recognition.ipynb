{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T14:28:57.296197Z",
     "start_time": "2024-02-21T14:24:17.841480Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 137s 1us/step\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4194816   \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4200842 (16.02 MB)\n",
      "Trainable params: 4200842 (16.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 16s 50ms/step - loss: 1.7905 - accuracy: 0.3601 - val_loss: 1.4854 - val_accuracy: 0.4730\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.4277 - accuracy: 0.4942 - val_loss: 1.3708 - val_accuracy: 0.5118\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 6s 21ms/step - loss: 1.2920 - accuracy: 0.5438 - val_loss: 1.2014 - val_accuracy: 0.5738\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 1.1999 - accuracy: 0.5775 - val_loss: 1.1324 - val_accuracy: 0.5986\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.1256 - accuracy: 0.6064 - val_loss: 1.0822 - val_accuracy: 0.6208\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 6s 21ms/step - loss: 1.0632 - accuracy: 0.6262 - val_loss: 1.0744 - val_accuracy: 0.6230\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.0062 - accuracy: 0.6451 - val_loss: 1.0968 - val_accuracy: 0.6218\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.9459 - accuracy: 0.6715 - val_loss: 1.0238 - val_accuracy: 0.6395\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.9013 - accuracy: 0.6833 - val_loss: 1.0193 - val_accuracy: 0.6471\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.8584 - accuracy: 0.7023 - val_loss: 0.9765 - val_accuracy: 0.6634\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.8181 - accuracy: 0.7145 - val_loss: 1.0151 - val_accuracy: 0.6488\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.7760 - accuracy: 0.7309 - val_loss: 0.9689 - val_accuracy: 0.6693\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 6s 21ms/step - loss: 0.7356 - accuracy: 0.7424 - val_loss: 1.0025 - val_accuracy: 0.6642\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 6s 21ms/step - loss: 0.7058 - accuracy: 0.7537 - val_loss: 1.0024 - val_accuracy: 0.6642\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 6s 21ms/step - loss: 0.6710 - accuracy: 0.7659 - val_loss: 0.9749 - val_accuracy: 0.6759\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 6s 21ms/step - loss: 0.6283 - accuracy: 0.7828 - val_loss: 0.9796 - val_accuracy: 0.6747\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.6062 - accuracy: 0.7876 - val_loss: 1.0614 - val_accuracy: 0.6672\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.5812 - accuracy: 0.7989 - val_loss: 0.9697 - val_accuracy: 0.6837\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 6s 21ms/step - loss: 0.5479 - accuracy: 0.8084 - val_loss: 0.9869 - val_accuracy: 0.6819\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.5211 - accuracy: 0.8205 - val_loss: 1.1143 - val_accuracy: 0.6637\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 1.1283 - accuracy: 0.6524\n",
      "Test score: 1.1282918453216553\n",
      "Test accuracy: 0.652400016784668\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 5, 5, 64)          36928     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 2, 2, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, 2, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 202282 (790.16 KB)\n",
      "Trainable params: 202282 (790.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "# Now let's do a one-hot encoding and normalize the images:\n",
    "\n",
    "# convert to categorical\n",
    "Y_train = to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = to_categorical(y_test, NB_CLASSES)\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT,\n",
    "verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "# And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "NUM_TO_AUGMENT=5\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# augumenting\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "xtas, ytas = [], []\n",
    "for i in range(X_train.shape[0]):\n",
    "    num_aug = 0\n",
    "    x = X_train[i] # (3, 32, 32)\n",
    "    x = x.reshape((1,) + x.shape) # (1, 3, 32, 32)\n",
    "    for x_aug in datagen.flow(x, batch_size=1,\n",
    "        save_to_dir='preview', save_prefix='cifar', save_format='jpeg'):\n",
    "        if num_aug >= NUM_TO_AUGMENT:\n",
    "            break\n",
    "    xtas.append(x_aug[0])\n",
    "    num_aug += 1\n",
    "    \n",
    "#fit the dataget\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# train\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "batch_size=BATCH_SIZE), samples_per_epoch=X_train.shape[0],\n",
    "epochs=NB_EPOCH, verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T14:24:03.412222Z",
     "start_time": "2024-02-21T14:24:03.402495Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is an image recognition algorithm from Deep Learning With Keras by Gulli and Pal. The algorithm is trained on the CIFAR-10 dataset that contains 60000 images that span 10 categorical classes (some examples of the categories include: airplane, automobile, bird, cat, deer, etc.) and it aims to train the machine to categorize novel images based on previous learning of attributes shared by other images that category (Gulli & Pal, 2017).\n",
    "\n",
    "There are ethical and privacy considerations that should be taken into account when working with image recognition AI, especially if the technology is used for more significant uses including facial recognition, for example. Image recognition algorithms can result in privacy concerns when the subject has not explicitly given permission for their image to be used with the technology. If the algorithm was instead trained on faces, permission would be required and the context of the use of the images should be explained to the subject so that they can make an informed decision on whether they wish to participate to comply with GDPR transparency requirements. Specifically, The GDPR requires that software accessed by the public must clearly state the context and intended use of personal information in clear language (Recital 58 - the Principle of Transparency - General Data Protection Regulation (GDPR), 2019).  According to this law, without explicit permission from the subject, private and personally identifying data including photography may breach privacy or copyright laws.\n",
    "\n",
    "Another ethical issue that arises is the potential for copyright infringement. Images such as photography featuring famous actors or celebrities are often copyrighted. Using copyrighted images requires additional permission and licensing for use by artificial intelligence for these purposes as well. To ensure compliance with copyright laws, open-source images or licensed images should be used in accordance with the license agreement. \n",
    "\n",
    "Finally, image recognition algorithms can also pose ethical concerns including discrimination if they are not properly implemented, trained, and maintained (Johnson, 2023). If data is not large and diverse, discriminatory judgments maybe made and inferred by artificial intelligence that categorizes by gender, race, or age, for example (SITNFlash, 2020). AI companies and institutions that use poorly trained algorithms that lead to discriminatory practices may find themselves liable for discriminatory actions that are made on these bases and efforts should always be made to provide holistic and well-rounded data to prevent these inequities in AI. \n",
    "\n",
    "**References**\n",
    "\n",
    "\n",
    "Gulli, A., & Pal, S. (2017). *Deep Learning with Keras.* Packt Publishing Limited. ISBN: 978-1-78712-842-2.\n",
    "\n",
    "Johnson, A. (2023, May 25). Racism and AI: Here’s how it’s been criticized for amplifying bias. *Forbes.* https://www.forbes.com/sites/ariannajohnson/2023/05/25/racism-and-ai-heres-how-its-been-criticized-for-amplifying-bias/?sh=4b623d1d269d\n",
    "\n",
    "*Recital 58 - The Principle of Transparency - General Data Protection Regulation (GDPR)*. \n",
    "(2019, September 3). General Data Protection Regulation (GDPR). https://gdpr-\n",
    "info.eu/recitals/no-58/\n",
    "\n",
    "SITNFlash. (2020, October 26). *Racial discrimination in face recognition technology - Science in the news.* Science in the News. https://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology/#:~:text=Face%20recognition%20algorithms%20boast%20high,and%2018%2D30%20years%20old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
